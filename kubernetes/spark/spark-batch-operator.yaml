apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: job-pyspark-2
  namespace: processing
spec:
  type: Python
  pythonVersion: "3"  
  mode: cluster
  image: docker.io/cleyber/spark-operator:v3.0.0-gcp
  imagePullPolicy: Always
  mainApplicationFile: gs://edc-scripts/converte_parquet.py
  sparkVersion: "3.0.0"
  hadoopConf:
    "fs.gs.project.id": "edc-desafio-igti"
    "fs.gs.system.bucket": "desafio-igti"
    "google.cloud.auth.service.account.enable": "true"
    "google.cloud.auth.service.account.json.keyfile": google-credential

  driver:
    cores: 1
    memory: "4g"
    coreLimit: "1200m"
    envVars:
      GCS_PROJECT_ID: edc-desafio-igti
    envSecretKeyRefs:
      GCP_Account:
        name: gcp-credentials
        key: google-credential
  executor:
    instances: 3
    cores: 3
    memory: "4g"
    envVars:
      GCS_PROJECT_ID: edc-desafio-igti
    envSecretKeyRefs:
      GCP_Account:
        name: gcp-credentials
        key: google-credential